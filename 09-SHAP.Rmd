# Mô hình Machine learning khả diễn

## Giới thiệu

...

## Bối cảnh của thí nghiệm

...

```{r,message = FALSE,warning=FALSE}
# Thao tác dữ liệu và đồ họa
library(tidyverse)

# Machine learning
library(tidymodels)
library(SHAPforxgboost)

# Đồ họa
library(lvplot)
library(GGally)
library(patchwork)
```

...

```{r}
df = read.csv('Blastocyte_quality.csv', 
              sep = ';', dec = ',', 
              fileEncoding = 'UTF-8-BOM')%>%na.omit()

names(df)
```


Giải thích:

df = read.csv('Blastocyte_quality.csv', sep = ';', dec = ',', fileEncoding = 'UTF-8-BOM') %>% na.omit(): Đọc dữ liệu từ file CSV với dấu phân cách là ;, dấu thập phân là , và loại bỏ các dòng có giá trị NA.

names(df): In ra tên của các cột trong dataframe df.

## Kế hoạch phân tích: 

...

## Chuẩn bị và thăm dò dữ liệu

...

```{r}
df$Blast_ICM = as.factor(df$Blast_ICM)
df$Blast_TE = as.factor(df$Blast_TE)

df$Prim_Inf %<>% as.factor()%>%
  recode_factor(.,`0` = "Primary",
                `1` = "Secondary")

df$Trigger%<>% as.factor()%>%
  recode_factor(.,`a` = "Agonist", 
                `h` = "hCG",
                `d` = "Dual")

df$ClinPreg = as.factor(df$ClinPreg)
```

Giải thích:

Biến Đổi Dữ liệu

df$Blast_ICM = as.factor(df$Blast_ICM): Chuyển đổi cột Blast_ICM thành loại dữ liệu factor.
df$Blast_TE = as.factor(df$Blast_TE): Chuyển đổi cột Blast_TE thành loại dữ liệu factor.

%<>% là toán tử "compound assignment" từ thư viện magrittr, nó áp dụng một hàm cho một biến và gán kết quả trở lại vào chính biến đó.

df$Prim_Inf %<>% as.factor() %>% recode_factor(., 0= "Primary",1 = "Secondary"): Chuyển đổi cột Prim_Inf thành factor, sau đó mã hóa lại các giá trị của nó từ 0 và 1 thành "Primary" và "Secondary".

df$Trigger %<>% as.factor() %>% recode_factor(., a= "Agonist",h= "hCG",d = "Dual"): Chuyển đổi cột Trigger thành factor, sau đó mã hóa lại các giá trị của nó.

df$ClinPreg = as.factor(df$ClinPreg): Chuyển đổi cột ClinPreg thành loại dữ liệu factor.

...

```{r}
str(df)
```

...

### Các thông số định tính, rời rạc

...

```{r}
class_pals = c('#fc0341','#03adfc')

df%>%mutate(Day = factor(.$Day_BVitrif),
            Size = factor(.$Blast_size),
            Size_chang = factor(.$dSize),
            ICM_chang = factor(.$dICM),
            TE_chang = factor(.$Blast_TE))%>%
  gather(Day,Size,Blast_TE,Blast_ICM,
         Size_chang,ICM_chang,TE_chang,
         Prim_Inf,Trigger,
            key="Feature",
            value="Status")%>%
  ggplot(aes(x=Status,
             fill=ClinPreg))+
  geom_bar(stat="count",
           position="fill",
           alpha=0.5,
           col="black")+
  coord_flip()+
  scale_y_continuous(labels=NULL)+
  theme_bw()+
  facet_wrap(~Feature,scales="free",ncol=3)+
  scale_fill_manual(values=class_pals)
```

...

### Các biến số liên tục

...

```{r}
df%>%tidyr::gather(Age,BMI,AFC,Blasturation, 
                   key = "Feature", 
                   value = "Score")%>%
  ggplot()+
  geom_density(aes(x=Score,
                   fill=ClinPreg),
               alpha=0.5)+
  theme_bw(10)+
  scale_fill_manual(values=class_pals)+
  facet_wrap(~ Feature,
             ncol=2,
             scales = "free")
```

...

```{r}
binomial_smooth <- function(...) {
  geom_smooth(method = "glm", 
              formula = y ~ splines::bs(x,3),
              method.args = list(family = "binomial"), ...)
}

df%>%tidyr::gather(Age,BMI,AFC,Blasturation,
                   key = "Feature", 
                   value = "Score")%>%
  mutate(CP = as.numeric(ClinPreg)-1)%>%
  ggplot(aes(x=Score,
             y=CP)
         )+
  geom_point(aes(color = CP),
               alpha=0.3)+
  binomial_smooth(color = "black",
                  fill = "red",
                  alpha = 0.4)+
  theme_bw(10)+
  scale_color_gradient(low=class_pals[1],
                       high=class_pals[2])+
  facet_wrap(~ Feature,
             ncol=2,
             scales = "free")
```

...

```{r,cache =T}
plotfuncmid <- function(data,mapping){
  p <- ggplot(data = data,
              mapping=mapping)+
    geom_density(aes(fill=data$ClinPreg),
                 alpha=0.3,
                 color="black")+
    scale_fill_manual(values=class_pals)
  p
}

plotfuncLow <- function(data,mapping){
  p <- ggplot(data = data,
              mapping=mapping)+
    stat_density2d(geom="polygon",
                   aes(fill=data$ClinPreg,
                       alpha = ..level..))+
    scale_fill_manual(values=class_pals)+
    scale_color_manual(values=class_pals)
  p
}

plotfuncUp <- function(data,mapping){
  p <- ggplot(data = data,
              mapping=mapping)+
    geom_jitter(size = 0.05,
                alpha = 0.1,
                aes(color=data$ClinPreg))+
    geom_smooth(se=T,
                alpha=0.5,
                size = 0.5,
                aes(color=data$ClinPreg, 
                    fill = data$ClinPreg)
                )+
    scale_color_manual(values=class_pals)+
    scale_fill_manual(values=class_pals)
  p
}

library(GGally)

ggpairs(data = df,
        columns=c(2:4,10,12,14),
        lower=list(continuous=plotfuncLow),
        diag=list(continuous=plotfuncmid),
        upper = list(continuous=plotfuncUp))+
  theme_bw(5)
```

...

## Phân chia dữ liệu

...

```{r}
set.seed(12345)
init_split = df%>%initial_split(prop = 0.7)

train_data <- training(init_split)
test_data <- testing(init_split)
```

Giải thích:

set.seed(12345): Đảm bảo khả năng tái lập kết quả của các quy trình ngẫu nhiên.

Phân chia Dữ liệu

init_split = df %>% initial_split(prop = 0.7): Chia dữ liệu gốc dataframe df thành tập huấn luyện và tập kiểm định với tỷ lệ 70%-30%.

train_data <- training(init_split): Lấy tập huấn luyện.

test_data <- testing(init_split): Lấy tập kiểm định.

## Thiết lập mô hình phân loại

### Bước 3a) Công đoạn sơ chế dữ liệu

...

```{r}
train_recipe <- 
  recipe(ClinPreg ~ ., 
         data = train_data) %>% 
  step_dummy(all_nominal_predictors())
```

Giải thích: 

train_recipe: Tạo recipe để định rõ quy trình tiền xử lý dữ liệu. Ở đây, ta muốn chuyển đổi các biến định danh thành dạng "dummy variables".


### Khởi tạo mô hình XGBoost

...

```{r}
xgboost_model <- boost_tree(
  mode = "classification",
  trees = 500,
  tree_depth = 5,
  sample_size = 0.8,
  learn_rate = 0.01,
  engine = "xgboost")
```

Giải thích:

Khởi tạo một mô hình XGBoost

xgboost_model: Định nghĩa một mô hình XGBoost với các tham số (hyper parameter) được đặc tả.

Chi tiết về các tùy chỉnh trong hàm:

mode = "classification": Chỉ định loại mô hình mà bạn muốn xây dựng. Ở đây, nó được đặt là "classification" cho bài toán phân loại.

trees = 500: Số lượng "trees" hay số lượng vòng lặp boosting. Mô hình sẽ được huấn luyện với 500 cây quyết định.

tree_depth = 5: Độ sâu tối đa của từng cây quyết định. Một độ sâu lớn có thể làm mô hình phức tạp hơn và dễ bị overfit, trong khi độ sâu thấp có thể làm mô hình không đủ mạnh để học dữ liệu.

sample_size = 0.8: Tỷ lệ dữ liệu được lấy mẫu từ tập huấn luyện để xây dựng mỗi cây. Tùy chỉnh này là một phần của kỹ thuật "bagging" (tái chọn mẫu rồi kết hợp), giúp giảm overfit.

learn_rate = 0.01: Tốc độ học (learning rate), kiểm soát mức độ cập nhật mô hình sau mỗi cây. Giá trị nhỏ sẽ làm cho mô hình cập nhật chậm, có thể cần nhiều vòng lặp hơn nhưng thường sẽ cho kết quả tốt hơn.

engine = "xgboost": Thư viện mà bạn muốn sử dụng để thực hiện XGBoost. Ở đây, nó được đặt là "xgboost".

### Tạo workflow

...

```{r}
clinpreg_wf <- workflow() %>%
  add_recipe(train_recipe) %>%
  add_model(xgboost_model)
```

Tạo một workflow bằng cách kết hợp recipe và mô hình.

...

### Thực hiện kiểm định chéo lặp lại 10x10

...

## Các tiêu chí hiệu năng mô hình phân loại nhị phân

...

```{r, cache =T}
kfcv = vfold_cv(df, 
                v = 10,
                repeats = 10)

cv_res = clinpreg_wf%>%
  fit_resamples(resamples = kfcv, 
                metrics = metric_set(f_meas,
                                     bal_accuracy,
                                     sens, 
                                     spec,
                                     roc_auc
                                     ))
```


Cross-validation (kiểm định chéo)

kfcv = vfold_cv(df, v = 10, repeats = 10): Thực hiện k-fold cross-validation (kiểm định chéo 10-khối, 10 lần lặp lại).

cv_res: Sử dụng workflow để fit mô hình trên các khối dữ liệu và tính toán các chỉ số đánh giá.

...

```{r}
cv_res_extract = cv_res$.metrics%>%
  bind_rows()

cv_res_extract %>% 
  group_by(.metric)%>%
  summarize(n = n(),
            mean = mean(.estimate),
            sd = sd(.estimate),
            median = median(.estimate),
            p5 = quantile(.estimate, 0.05),
            p95 = quantile(.estimate, 0.95)
            )%>%
    knitr::kable(digits = 3)
```

Tổng kết Kết quả Cross-validation

cv_res_extract %>% group_by(.metric) %>% summarize(...): Tính toán các giá trị thống kê cho từng chỉ số đánh giá.
...

```{r}
cv_res_extract %>%
  ggplot(aes(x = .metric, y = .estimate))+
  geom_lv(aes(fill = ..LV..),
          col = 'black',
          show.legend = F)+
  coord_flip()+
  scale_fill_brewer(palette = "Reds", direction = -1)+
  theme_bw()
```

Biểu đồ Kết quả

Một biểu đồ lvplot (geom_lv) hiển thị sự phân bố của các chỉ số đánh giá.

...

## Huấn luyện mô hình trên toàn thể dữ liệu tập Train

...

```{r, cache =T}
fit <- clinpreg_wf %>%
  fit(train_data)

fit_xgb = extract_fit_engine(fit)
```

Dự đoán và Đánh giá
fit <- clinpreg_wf %>% fit(train_data): Áp dụng toàn bộ workflow vào tập huấn luyện.

...

```{r}
fit_xgb$evaluation_log %>%
  ggplot()+
  geom_path(aes(x = iter, y = training_logloss), 
            col = "red")+
  scale_x_continuous(breaks = seq(0,500,50))+
  scale_y_continuous(breaks = seq(0.2,0.8,0.025))+
  labs(x = "Iterations", y = "binary logloss")+
  theme_bw(10)
```

Vẽ biểu đồ training curve

...

## Kiểm định độc lập hiệu năng mô hình

...

```{r, cache =T}
valid_pred_p = predict(fit, new_data = test_data, type ="prob")
valid_pred_c = predict(fit, new_data = test_data)

valid_out = tibble(truth = test_data$ClinPreg,
                   neg = valid_pred_p$.pred_0,
                   pos = valid_pred_p$.pred_1,
                   pred = valid_pred_c$.pred_class)

conf_mat(valid_out, 
         truth = truth, 
         estimate = pred)
```

valid_pred_p và valid_pred_c: Dự đoán xác suất và lớp từ tập kiểm định.

conf_mat: Tính toán confusion matrix.

```{r}
bind_rows(f_meas(valid_out,truth,pred),
          bal_accuracy(valid_out,truth,pred),
          sens(valid_out,truth,pred),
          spec(valid_out,truth,pred),
          precision(valid_out,truth,pred),
          npv(valid_out,truth,pred),
          ppv(valid_out,truth,pred),
          roc_auc(valid_out, 
                  truth, pos, 
                  event_level="second"))%>%
  knitr::kable(digits = 3)
```

bind_rows(...): Tính toán và hiển thị các chỉ số đánh giá hiệu năng trên tập kiểm định.

Cụ thể, các chỉ số sau đây sẽ được tính toán:

f_meas: F-measure, một chỉ số đánh giá tổng quan cho mô hình phân loại, xein xem ý nghĩa trong sách in.

bal_accuracy: độ chính xác cân bằng - Balanced Accuracy. Chỉ số này là hữu ích khi dữ liệu không cân đối.

sens: Sensitivity hoặc True Positive Rate (xem ý nghĩa trong sách in)

spec: Specificity hoặc True Negative Rate,

precision: Tỷ lệ true positive trên tổng số dự đoán positive.

npv: Negative Predictive Value, tỷ lệ true negative trên tổng số dự đoán negative.

ppv: Positive Predictive Value, giống như precision, là tỷ lệ true positive trên tổng số dự đoán positive.

roc_auc: Diện tích dưới đường cong ROC (Receiver Operating Characteristic curve), một chỉ số đánh giá khả năng phân loại của mô hình. Giá trị càng gần 1, mô hình càng tốt.

Các chỉ số này được tính toán dựa trên các dự đoán và giá trị thực tế từ tập kiểm tra (test_data), và sau đó được kết hợp vào một bảng dữ liệu duy nhất bằng hàm bind_rows. 

...

```{r}
two_class_curve <- roc_curve(valid_out, 
                             truth, pos, 
                             event_level="second")

autoplot(two_class_curve)
```

Đoạn code này vẽ biểu đồ ROC
...

## Phân tích hậu kiểm bằng kỹ thuật SHAP

...

### Giới thiệu về phương pháp diễn giải mô hình SHAP

...

```{r, cache =T}
log_mod = glm(formula = ClinPreg ~ .,
              data = train_data,
              family = "binomial")

tidy(log_mod)%>%
  knitr::kable(digits = 3)
```

...

## Vai trò của các thông số đóng góp vào kết quả tiên lượng

...

```{r, cache =T}
X_train <- bake(
  prep(train_recipe), 
  has_role("predictor"),
  new_data = train_data, 
  composition = "matrix"
)

X_test <- bake(
  prep(train_recipe), 
  has_role("predictor"),
  new_data = test_data, 
  composition = "matrix"
)
```

Đoạn code này sử dụng hàm bake từ thư viện tidymodels để áp dụng các bước tiền xử lý đã được định nghĩa trong train_recipe lên tập dữ liệu train_data và test_data:

prep(train_recipe): Hàm prep chuẩn bị "recipe" cho việc áp dụng các bước tiền xử lý. Nói cách khác, nó nhận diện các tham số cần thiết từ tập dữ liệu huấn luyện (train_data) để có thể áp dụng các bước tiền xử lý đó lên bất kỳ tập dữ liệu nào khác.

has_role("predictor"): Chỉ định rằng chúng ta chỉ muốn lấy các cột có vai trò là "predictor" (yếu tố dự báo) từ tập dữ liệu, tức là ta loại trừ những biến không phải là yếu tố dự báo

new_data = train_data và new_data = test_data: Đây là tập dữ liệu mà các bước tiền xử lý sẽ được áp dụng lên.

composition = "matrix": Chỉ định rằng đầu ra cần phải là một matrix. Điều này là cần thiết đối với nhiều thuật toán học máy như XGBoost, vì chúng yêu cầu đầu vào dưới dạng ma trận.

Kết quả là, X_train và X_test sẽ là các ma trận chứa dữ liệu đã qua tiền xử lý từ train_data và test_data. Những cột trong những ma trận này sẽ tương ứng với các biến dự đoán ("predictors") và đã được xử lý theo các bước tiền xử lý định nghĩa trong train_recipe.

...

```{r, cache =T}
shap_data <- shap.prep(fit_xgb, 
                  X_train = X_train)

head(shap_data)
```


Giải thích

Đoạn code trên sử dụng SHAP (SHapley Additive exPlanations) để giải thích các dự đoán của mô hình XGBoost (được lưu trong biến fit_xgb). 

shap.prep: Hàm này chuẩn bị dữ liệu SHAP từ mô hình XGBoost.
fit_xgb: Đây là mô hình XGBoost đã được huấn luyện.
X_train: Ma trận dữ liệu đầu vào để tính SHAP score (đây cũng là dữ liệu vốn được sử dụng để huấn luyện mô hình) 

...

```{r, cache =T}
shap.plot.summary(shap_data)+
  scale_color_gradient2(low = "#078fe3",
                        mid = "#8007e3",
                        midpoint = 0.5,
                       high = "#e30750")
```




Vẽ biểu đồ SHAP Summary

Biểu đồ này hiển thị mức độ đóng góp/tầm quan trọng của từng biến đầu vào của mô hình. Mỗi dòng trên biểu đồ đại diện cho một biến (yếu tố dự báo). Các điểm trên dòng có màu tương ứng với giá trị của biến trên thang đo chuẩn hóa: cao (màu đỏ) hoặc thấp (màu xanh).
...

```{r, cache =T}
shap_data%>%ggplot(aes(x = reorder(variable, mean_value),
                  y = value))+
  geom_lv(aes(fill = mean_value),
               col = "black",
              alpha = 0.5)+
  scale_fill_gradient2(low="gold",
                       mid="red",
                       high="purple",
                       midpoint = 0.1)+
  scale_y_continuous(breaks = seq(-1,2,0.5))+
  labs(x = "Features", y = "SHAP value")+
  coord_flip()+
  theme_bw()
```

...

```{r, cache =T}
shap.importance(shap_data, 
                names_only = FALSE, 
                top_n = Inf)%>%
  ggplot(aes(x = reorder(variable,mean_abs_shap), 
             y = mean_abs_shap))+
  geom_bar(aes(fill = mean_abs_shap),
           stat="Identity",
           col = "black",
           alpha = 0.8,
           show.legend = F)+
  geom_text(aes(label=round(mean_abs_shap,3)), 
            vjust=0.15, 
            hjust=-0.15,
            size=3.5)+
  scale_y_continuous(limits = c(0,0.25))+
  labs(x = "Features")+
  coord_flip()+
  scale_fill_gradient2(low="gold",
                        mid="red",
                        high="purple",
                        midpoint = 0.1)+
  theme_bw()
```

...

```{r, cache =T}
shap_values <- shap.values(xgb_model = fit_xgb, 
                           X_train = X_train)
```


```{r, cache =T}
dpls = list()
# Step 4: Loop over dependence plots in decreasing importance
i=1
for (v in shap.importance(shap_data, names_only = TRUE)) {
  p = shap.plot.dependence(shap_data, 
                            v, color_feature = v, 
                            alpha = 0.5, 
                            jitter_width = 0.1,
                           size = 0.5)
  dpls[[i]] = p
  i = i+1
  print(p)
}
```

...

```{r, print = F}
# dpls[c(4,5,6,11)]
```

...

```{r,cache =T}
shap_int <- shap.prep.interaction(xgb_model = fit_xgb, 
                                  X_train = X_train)

shap.plot.dependence(data_long = shap_data,
                     data_int = shap_int,
                     x= "AFC", y = "Age", 
                     color_feature = "AFC")
```

...

### SHAP score có thể dùng để phân cụm dữ liệu

...

```{r,cache =T}
plot_data <- shap.prep.stack.data(shap_contrib = shap_values$shap_score, 
                                  top_n = 7, 
                                  n_groups = 4)

shap.plot.force_plot(plot_data, 
                     zoom_in_location = 500,
                     y_parent_limit = c(-0.1,0.1))

shap.plot.force_plot_bygroup(plot_data)
```

...

## Bàn luận: 

### Ưu điểm và nhược điểm của mô hình XGboost

...

### Ưu điểm và nhược điểm của kỹ thuật SHAP

...

### Diễn giải cơ chế hoạt động của mô hình ở cấp độ cá thể:

...

```{r, cache =T}
library(shapviz)

shaps <- shapviz(fit_xgb,
                X_pred = X_test)

sv_force(shaps, row_id = 150)
sv_waterfall(shaps, row_id = 150)
```

...

```{r,cache =T}
sv_force(shaps, row_id = 20)
sv_waterfall(shaps, row_id = 20)
```

...

## Kết luận

...

## Thông điệp rút gọn làm hành trang

...
